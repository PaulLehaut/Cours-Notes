\documentclass{article}
\usepackage{mesraccourcis}

\title{Stochastic Process and Applications}
\author{Paul Lehaut}


\begin{document}
\newcommand{\CM}{chaîne de Markov}

\maketitle
\newpage
\tableofcontents
\newpage

\section{Chapitre 1: Rappels}
\subsection{Mesure}
Soit ($\Omega,\mathcal{F}$) un espace mesurable.
\medskip

\Def
\smallskip 
\newline
Une fonction $\mu: \mathcal{F} \longrightarrow [0,+\infty]$ est dite $\sigma$-additive si pour toute collection dénombrable ($A_i, \ i\in I$)
d'ensembles mesurables deux à deux disjoints, on a:
$$\mu (\bigcup_{i\in I}A_i) = \sum_{i\in I}\mu(A_i).$$
\newline
Une mesure $\mu$ sur ($\Omega,\mathcal{F}$) est \sigadd, à valeur dans $[0,+\infty]$, définie sur $\mathcal{F}$ telle que:
$\mu(\varnothing)=0.$ On dit que ($\Omega,\mathcal{F}, \mu$) est un espace mesuré, $A\in \mathcal{F}$ est de mesure nulle si $\mu(A)=0$.
\newline
$\mu$ est dite $\sigma$-finie si il existe $(\Omega_n, \ n\in \mathbb{N})$ telle que:
$$\bigcup_{n\in\N}\Omega_n=\Omega \ \ \text{et} \ \ \forall n \in \N,\ \mu(\Omega_n)<+\infty.$$
\newline
Une mesure de probabilité $\Prob$ est une mesure telle que $\Prob(\Omega)=1$.
\bigskip
\newline
Soit donc $\mu$ une mesure sur ($\Omega,\mathcal{F}$).
\medskip

\Prop
\smallskip
\newline
On a les propriétés suivantes:

$$\mu(A\cup B)+ \mu(A\cap B)=\mu(A)+\mu(B)$$
$$A\subset B \implies \mu(A)\le \mu(B)$$
$$\text{Convergence monotone: pour }(A_n, \ n\in \N) \text{ telle que } \forall n\in\N , \ A_{n+1}\subset A_n, \text{ alors } \mu(\bigcup_{n\in \N}A_n)=\lim_{n\to \infty}\mu(A_n)$$
$$\text{Si } (A_i, i \in I) \text{ est une collection dénombrable d'ensembles mesurables, alors il vient: } \mu(\bigcup_{i\in I}A_i)\le \sum_{i\in I}\mu(A_i).$$
\bigskip

\Def 
\smallskip
\newline
Les événements $(A_i, i\in I)$ sont indépendants si, pour tout sous-ensemble fini $J\subset I$, on a:
$$\Prob (\bigcap_{j\in J}A_j)=\prod_{j\in J} \Prob (A_j).$$
\bigskip
\subsection{Fonctions Mesurables}
Soient $(S,\mathcal{S})$ et $(E,\mathcal{E})$ deux espaces mesurables. Soit $f$ une fonction de S dans E, alors:
$$\{f^{-1}(A), \ A\in \mathcal{E}\}=\sigma(f)$$
est une \sigalg.
\bigskip

\Def \ Fonction mesurable
\smallskip
\newline
La fonction $f$ est dite mesurable si $\sigma(f)\subset \mathcal{S}$.
\bigskip
\newline
Si $\mu$ est une mesure sur $(E,\mathcal{E})$ et que f est mesurable, alors $\mu_f=\mu\circ f^{-1}$ est une mesure sur ($S,\mathcal{S}$).
\newline
Une fonction continue définie sur un espace topologique et prenant ses valeurs dans un espace topologique est mesurable au sens de la \sigalg \ borélienne.
\newline
Pour $f$ et $g$ des fonctions mesurables à valeurs réelles définies sur le même espace mesurable, alors les fonction $fg$ et $\max (f,g)$ sont mesurables.
Si par ailleurs ses fonctions ne prennent pas de valeurs infinies, alors la fonction $f+g$ est mesurable.
\newline 
La composition de fonctions mesurables est également mesurable.
\bigskip

\Prop 
\smallskip
\newline
Soit $(f_n)$ une suite de fonctions réelles mesurables, alors les fonctions $\lim\inf f_n$ et $\lim\sup f_n$ sont mesurables, en particulier, si $(f_n)$ converge simplement, alors sa limite est mesurable.
\bigskip

\Def \ Variable Aléatoire
\sskip
Une variable aléatoire X définie de $\Omega$ dans $E$ est une fonction mesurable définie sur ($\Omega,\mathcal{F}$) à valeurs dans ($E,\mathcal{E}$).
\newline
X est dite indépendante de la \sigalg \ $\mathcal{H}$ si, pour tout $(A,B)\in \mathcal{E}\times \mathcal{H}$, les événements $\{X\in A\}$ et $B$ sont indépendants.
\bigskip
\subsection{Théorème de convergence pour l'intégration}
Soit $(f_n)$ une suite de fonctions mesurables à valeurs réelles. Cette suite converge \pp \ si $$\lim\inf f_n = \lim\sup f_n \text{ \pp.}$$
On rappelle que la limite de cette suite de fonction est alors mesurable.
\bigskip

\Theo \ Convergence monotone
\sskip 
Soit ($f_n, \ n\in \N$) une suite de fonctions mesurables à valeurs réelles telle que pour tout $n\in \N, \ 0\le f_n\le f_{n+1}$ \pp, alors il vient:
$$\lim_{n\to\infty}\int f_n d\mu=\int \lim_{n\to\infty} f_n d\mu.$$
\bskip 
Le lemme de Fatou donne, pour ($f_n, n$) une suite de fonctions mesurables et positives presque partout, alors il vient:
$$\lim\inf\int f_n d\mu\ge \int \lim\inf f_n d\mu.$$
\bigskip

\Theo \ Convergence dominée de Lebesgue
\sskip 
Soient $f, \ g$ deux fonctions à valeurs réelles mesurables, soit $(f_n)$ une suite de fonctions à valeurs réelles mesurables.
\newline
On suppose que, pout tout $n\in \N$, on a \pp \ $|f_n|\le g$, que f désigne la limite de $(f_n)$ et que g est intégrable, alors:
$$\lim_{n\to\infty}\int f_nd\mu=\int fd\mu.$$

\subsection{Espaces $L^p$}
On commence par rappeler les inégalités suivantes pour $f$ et $g$ des fonctions mesurables à valeurs réelles:
\bigskip

Inégalité de Hölder: Soient $p,g\in (1,+\infty)$ tels que $\frac{1}{p}+\frac{1}{q}=1$, supposons que $|f|^p$ et $|g|^q$ soient intégrables, alors $fg$ est intégrable et on a:
$$\int |fg|d\mu\le(\int|f|^pd\mu)^{1/p}(\int|g|^qd\mu)^{1/q}.$$
\bigskip

Inégalité de Cauchy-Schwarz: Supposons que $f$ et $g$ soient de carré intégrable, alors fg est intégrable et on a:
$$\int |fg|d\mu\le (\int f^2d\mu)^{1/2}(\int g^2d\mu)^{1/2}$$
on a égalité si et seulement si $f$ et $g$ sont propotionnelles \pp.
\bigskip

Inégalité de Minkowski: Soit $p\in [1,+\infty)$, supposons que $|f|^p$ et $|g|^p$ soient intégrables, alors on a:
$$(\int |f+g|^pd\mu)^{1/p}\le(\int |f|^pd\mu)^{1/p}+(\int |g|^pd\mu)^{1/p}.$$

\Prop 
\sskip 
Soit $p\in [1,+\infty)$, l'\evn \ ($L^p, ||\cdot||_p$) est complet.
\bigskip 

\Theo \ Fubini
\sskip 
Soient $\nu$ et $\mu$ deux mesures $\sigma$-finies respectivement sur ($E, \mathcal{E}$) et ($S, \mathcal{S}$), alors:

-il existe une unique mesure sur ($E\times S, \mathcal{E}\otimes\mathcal{S}$), notée $\nu\otimes\mu$, telle que:
$$\forall (A,B)\in \mathcal{E}\times\mathcal{S}, \ \nu\otimes\mu (A\times B)=\nu(A)\mu(B)$$
c'est la mesure produit

-Soit f une fonction à valeurs réelles défnie sur $E\times S$, alors:
$$\int f(x,y)\nu\otimes\mu(dx,dy)=\int\int f(x,y)\mu(dy)\nu(dx)=\int\int f(x,y)\nu(dx)\mu(dy).$$
\bigskip
\subsection{Espérance, Variance et Inégalités}
Soit X une variable aléatoire, soit $f$ une fonction à valeurs réelles, si $\E (f(X))$ est bien définie, alors on a:
$$\E(f(X))=\int f(x)\Prob_X(dx).$$
\bigskip

Inégalité de Tchebychev: Soit X une VA$\R$, soit, $a>0$, alors:
$$\Prob (|X|\ge a )\le \frac{E(X^2)}{a^2}.$$
\bigskip

Inégalité de Jensen: Soit X une VA$\R^d$ intégrable, soit $f$ une fonction à valeurs réelles convexe définie sur $\R^d$, alors $\E(f(X))$ est bien définie et:
$$f(\E(X))\le \E(f(X)).$$
\bigskip 

\section{Espérance Conditionnelle}
\subsection{Espérance Conditionnelle}
On s'intéresee à une VA$\R$ définie sur ($E,\mc F$) dont l'espérance est bien définie ainsi qu'à $\mc H\subset F$ une \sigalg.
\bigskip 

\Def \ Espérance conditionnelle
\sskip
On dit qu'une variable aléatoire $Z$, mesurable pour $\mc{H}$ telle que $\E(Z)$ soit bien définie, est l'espérance conditionnelle de $X$ par rapport à $\mc{H}$ si:
$$\E(X1_A)=\E(Z1_A), \ \forall A\in\mc{H}.$$
\bskip
Pour $Z$ et $Z'$ deux variables aléatoires $\mc H$ mesurables telles que leurs espérances soient bien définies et que:
$$\E(Z1_A)=\E(Z'1_A), \ \forall A\in \mc H$$
alors $Z=Z'$ \pp.
\bigskip 

\Theo \ Radon-Nikodym
\sskip 
Soient $\mu$ et $\nu$ deux mesures $\sigma$-finie sur $(\Omega, \mc H)$ telles que: $\nu(A)=0\implies\mu(A)=0$, alors il existe une fonction mesurable $f$ positive telle que:
$$\int_A fd\nu=\mu(A)$$
on note alors: $f=\frac{d\mu}{d\nu}$ et on l'appelle dérivée de Radon-Nikodym.
\bigskip 

\Prop
\sskip
Pour $X$ et $Y$ des VA$\R$ de carré intégrable alors:

-Si $X$ est positive presque partout, alors l'espérance conditionnelle de $X$ est positive presque partout.
\smallskip

-On a presque partout: $\E(aX+bY|\mc H)=a\E(X|\mc H)+ b\E(Y|\mc H)$.
\smallskip

-Soit $(X_n,\ n\in\N)$ une suite croissante de VA$\R$ positives de carré intégrable alors on a \pp :
$$\lim\E(X_n|\mc H)=\E(\lim X_n| \mc H).$$
\bigskip

\Prop 
\sskip 
L'espérance conditionnelle de $X$ par rapport à $\mc H$ existe toujours, par ailleurs on a:
$$\E(\E(X|\mc H))=\E(X)$$
donc l'intégrabilité de $X$ entraîne celle de $\E(X|\mc H)$.
\newline
\bigskip

\Prop
\smallskip

-Si $X$ est positive \pp alors son espérance conditionnelle l'est également.
\smallskip

-Si $X$ et $Y$ sont intégrables, alors, pour tout réels $a$ et $b$, on a :
$$\E(aX+bY|\mc H)=a\E(X|\mc H)+b\E(Y| \mc H)$$
et, si $X\le Y$ \pp, alors $\E(X|\mc H)\le \E(Y|\mc H)$ \pp.
\smallskip

-Soit $(X_n,\ n\in\N)$ une suite croissante de VA$\R$ positives \pp, alors on a \pp:
$$\lim\E(X_n|\mc H)=\E(\lim X_n|\mc H).$$
\smallskip

-Le lemme de Fatou s'écrit: Soit $(X_n,\ n\in\N)$ une suite de VA$\R$ positives \pp, alors on a \pp:
$$\E(\lim\inf X_n|\mc H)\le \lim\inf\E(X_n|\mc H).$$
\smallskip

-La convergence dominée de Lebesgue s'écrit: Soient $X,Y,(X_n)$ des VA$\R$ telles que $(X_n)$ converge vers $X$ \pp \ et $|X_n|\le Y$ avec $Y$ intégrable, alors on a :
$$\lim\E(X_n|\mc H)=\E(X|\mc H).$$
\bskip
Par ailleurs, les inégalités de Hölder, Cauchy-Schwarz, Minkowski et Jensen restent valables pour l'espérance conditionnelle.
\newline
De plus, pour $X$ et $Y$ deux VA$\R$ telles que $\E(X)$ et $\E(XY)$ soient bien définies et que $Y$ soit $\mc H$ mesurable, alors on a:
$$\E(XY)=\E(\E(X|\mc H)Y).$$
\bigskip

\Prop 
\sskip
On suppose X intégrable, alors:
\smallskip

-Si $X$ est $\mc H$ mesurable, alors: $\E(X|\mc H)=X$.
\smallskip 

-Si $X$ est indépendante de $\mc H$ alors: $\E(X|\mc H)=\E(X)$.
\smallskip

-Si $Y$ est une VA $\mc H$ mesurable telle que $\E(XY)$ soit bien définie, alors: $\E(YX|\mc H)=Y\E(X|\mc H)$.
\smallskip

-Si $\mc G\subset\mc H$ est une \sigalg, alors: $\E(\E(X|\mc H)|\mc G)=\E(X|\mc G)$.
\smallskip 

-Si $A\in \mc H$, alors: $\E(X|A)=\E(X1_A)\Prob(A)$.
\bigskip

\subsection{Espérance Conditionnée par une VA}
Soit $V$ une variable aléatoire définie sur $(E,\mc E)$, on note $\E(X|V)=\E(X|\sigma(V))$, si $\E(X)$ est bien définie, alors il existe une fonction mesurable $g$ définie sur E telle que: $\E(X|V)=g(V)$.
\sskip 
Si $V$ est discrète, alors:
$$g(v)=\frac{\E(X1_{V=v})}{\Prob(V=v)}=\E(X|V=v) \ \ \text{si } \Prob(V=v)>0, \ \ \text{et } g(v)=0 \ \ \text{sinon.}$$
\bigskip 

\section{Chaînes de Markov Discrètes}
Une chaîne de Markov est une suite de variables aléatoires $X=(X_n)$ qui représente l'évolution dynamique d'un système stochastique. La propriété fondamentale des chaînes de Markov est que l'état du système à l'instant $n$ ne dépend des états précédents qu'à travers $X_n$. C'est-à-dire que, conditionnellement à $X_n$, $(\ind X n)$ et $(X_{n+k})_k$ sont indépendants.
\sskip 
Dans ce qui suit on considère l'espace probabilisé $(\Omega, \mc F, \Prob)$ et l'espace $(E,\mc E)$ où $E$ est au plus dénombrable, sans précisions supplémentairtes les VAs seront définies de $\mc F$ dans $\mc E$.
\bigskip 

\subsection{Définitions et Propriétés}
Soit $X=(X_n)$ une chaîne de Markov, on définit l'ensemble des informations disponibles à l'instant $n$ par la \sigalg \ $\mc F_n$
\bigskip 

\Def \ Filtre 
\sskip 
Un filtre $\mathbb{F}=(\mc F_n)$ est une suite croissante de \sigalg \ incluses dans $\mc F$. Une suite de VAs $(X_n)$ est adaptée pour $\mathbb F$ si $X_n$ est $\mc F_n$ mesurable pour tout $n$.
\bigskip 

\Def 
\sskip 
Le processus $X=(X_n)$ est une chaîne de Markov qui respecte le filtre $\mathbb F$ si elle est adaptée pour ce filtre et si elle vérifie la propriété de Markov: pour tout $n$, conditionnellement à $X_n$, $\mc F_n$ et $(X_{n+k})_{k\in\N}$ sont indépendants.
\bigskip 

\Prop \ Définitions équivalentes
\sskip 
On suppose que $(X_n)$ est adaptée au filtre $\mathbb F$, alors on a les équivalences suivantes:
\begin{itemize}
    \item $(X_n)$ est une chaîne de Markov
    \item Pour tout $n$ et $B\in\sigma(X_k)_{k\ge n}$ on a $\Prob (B|\mc F_n)=\Prob(B|X_n)$
    \item Pour tout $n$ et $y\in E$ on a $\Prob (X_{n+1}=y|\mc F_n)=\Prob(X_{n+1}=y|X_n)$.
\end{itemize}
\bigskip
La proposition précédente nous permet d'introduire le lemme suivant: 
\smallskip

\underline{Lemme:}
\sskip 
Soient un espace mesurable $(S, \mc S)$ et $(U_n)$ une suite de VAs indépendantes à valeurs dans S. Soient $X_0$ une variable aléatoire à valeurs dans E indépendante de $(U_n)$ et $f$ une fonction mesurable définie de $E\times S$ dans $E$, on peut alors définir le système dynamique stochastique suivant: $X_{n+1}=f(X_n,U_{n+1})$ qui est une chaîne de Markov.
\bigskip

\Def \ Matrices de transition
\sskip 
Une chaîne de Markov $X$ sur $E$ a les matrices de transition $(P_n)_n$ si c'est une suite de matrices stochastiques sur E telle que: $\Prob (X_{n+1}=y | X_n)=P_{n+1}(X_n,y)$.
\sskip 
Une chaîne de Markov est homogène si $(P_n)$ est constante. 
\bigskip 

\Prop 
\sskip 
La distribution d'une chaîne de Markov homogène est caractérisée par sa matrice de transition $P$ et la distribution initiale de probabilité $\mu_0$ pour $X_0$.
\sskip 
De plus, pour tout $n\in\N^*$, $\ind x n\in E$, alors:
$$\Prob(X_0=x_0,...,X_n=x_n) = \mu_0(x_0)\prod_{k=1}^n P(x_{k-1},x_k).$$

\Prop 
\sskip 
Soit $(X_n)$ une chaîne de Markov de matrice de transition $P$, on note $\mu_n$ la densité de probabilité de $X_n$, soit $f$ une fonction bornée ou positive, alors:
\begin{itemize}
    \item $\mu_n=\mu_0 P^n$
    \item $\E(f(X_n))=\mu_n f$ et $\E(f(X_n)|X_0=x)=P^nf(x)$
    \item $\E(f(X_n)|\mc F_{n-1})=Pf(X_{n-1})$
    \item $\E(f(X_n)|X_0)=P^nf(X_0)$
    \item $\Prob(X_{n+k}=y|\mc F_n)=P^k(X_n,y)$
\end{itemize}
\bigskip
\subsection{Probabilité Invariante et Réversible}
On se donne dans cette partie une distribution de probabilité $\pi$ et une matrice stochastique P.
\bigskip 

\Def 
\sskip
$\pi$ est invariante pour $P$ si $\pi = \pi P$. P est dite réversible par rapport à $\pi$ si $\pi(x)P(x,y)=\pi(y)P(y,x)$.
\bskip
On remarque alors que si $P$ est réversible par rapport à $\pi$, alors $\pi$ est invariante par rapport à $P$.
\bigskip 
\subsection{Classification d'Etats}
On introduit les notation: $\E_x(X_n)= \E(X_n | X_0=x)$ et $\Prob_x(X_n)= \Prob(X_n | X_0=x)$.
\bigskip

\Def 
\sskip 
Un état $y$ est accessible depuis un état $x$, noté $x\rightarrow y$, si $\Prob_x (X_n = y) > 0$.
\sskip 
$x$ et $y$ communiques ($x\leftrightarrow y$) si $y$ est accessible depuis $x$ et inversement.
\smallskip

\Prop 
\sskip 
La relation $\leftrightarrow$ est une relation d'équivalence.
\smallskip 
On note alors $C_x$ la classe d'équivalence d'un état $x$.
\bigskip 

\Def \ Irréductibilité 
\sskip 
On dit qu'une \CM \ est irréductible si $E$ ne contient qu'une seule classe d'équivalence.
\bigskip 

\Def \ Classe fermée et état absorbant 
\sskip 
Soit un état $x$, on dit que $C_x$ est fermée si $C_x=\{y\in E| x\rightarrow y\}$. $x$ est un état absorbant si $C_x=\{x\}$ $C_x$ est fermée.
\bskip 
Si une chaîne de Markov possède au moins deux éléments et un état absorbant alors elle n'est pas irréductible.
\bigskip 

\Def \ Temps de retour, état transient et récurrent
\sskip 
On pose $T^x = \inf\{n\ge 1| X_n =x\}$. $x$ est dit transient si $\Prob(T^x=\pinf)>0$, il est dit récurrent si $\Prob(T^x=\pinf)=0$.
\bskip 
On peut alors noter $N^x=\sum_{n\in\N}1_{X_n =x}$ le nombre de passage en $x$.
\bigskip 

\Prop 
\sskip 
Soit $(X_n)$ une \CM \ de matrice de transition $P$, alors:
\begin{itemize}
    \item Si $x$ est récurrent, alors $\Prob(N^x=\pinf)=1$ et $\sum_n P^n(x,x)=\pinf$
    \item S'il est transient, alors $\Prob(N^x<\pinf)=1$ et $\sum_n P^n(x,x)<\pinf$
    \item Les états de $C_x$ sont ou tous transients ou tous récurrents
    \item Si $C_x$ est ouvert, alors ses états sont transients.
\end{itemize}
\bigskip 
\subsection{Théorèmes Asymptotiques}
On note, pour un état $x$, $\pi(x)=1/\E_x(T^x)$.
\bigskip 

\Def 
\sskip 
Un état récurrent $x$ est: récurrent nul si $\pi(x)=0$, récurrent positif si $\pi(x)>0$.
\bigskip 

\Theo 
\sskip 
Soit $(X_n)$ une \CM \ irréductible, alors elle est ou bien récurrente nulle, ou bien récurrente positive, ou bien transiente.
\sskip 
Si elle est récurrente nulle ou transiente, alors il n'y a pas de probabilité invariante. 
\sskip
On a finalement le résultat suivant:
\sskip 
$$\forall x\in E, \frac{1}{n}\sum_{k=1}^n 1_{X_k=x} \longrightarrow_{ps}\pi(x).$$

\Def \ Périodicité 
\sskip 
Soit $(X_n)$ une chaîne de Markov homogène de matrice de transition P. La période de $x$ est le PGCD de: 
$$\{n\in\N^*| \ P^n(x,x)>0\}$$
si cet ensemble est vide, alors $x$ est de périodicité infinie, l'état est apériodique si sa périodicité est 1.
\bigskip 

\Prop 
\sskip 
Si $x$ est de période finie $d$, alors il existe $n_0\in\N$ tel que $P^{nd}(x,x)>0$ pour tout $n\ge n_0$. Les éléments d'une même classe communicante sont de même période.
\bigskip 

\Theo
\sskip 
On suppose que $(X_n)$ est récurrente positive, alors:
\begin{itemize}
    \item $\pi$ est la seule mesure invariante de $(X_n)$ et $\pi (x)>0$ pour tout $x$
    \item pour toute fonction à valeurs réelles $f$ telle que $(\pi,f) = \E_\pi(f(X_n))$ soit bien définie, alors: $\frac{1}{n}\sum_{k=1}^nf(X_k)\rightarrow_{ps} (\pi, f)$
    \item si la châine est apériodique, alors on a la convergence en distribution $X_n\rightarrow\pi$ et $\lim\sum_{y\in E}|P^n(x,y)-\pi(y)|=0$.
\end{itemize}
\bigskip 
\section{Martingales}
\subsection{Temps d'Arrêt}
Dans toute la suite $\tau$ désignera un temps d'arrêt.
\smallskip 

\Def \ Temps d'arrêt 
\sskip 
Il s'agit d'une variable aléatoire définie sur une filtration $\mathbb{F} $ si $\{\tau\le n\}\in\mc F_n$ pour tout $n$. $\tau$ est à valeur dans $\bar \N$.
\bigskip 

\underline{Lemme:}
\sskip 
$\tau$ est un temps d'arrêt si et seulement si $\{\tau> n\}\in\mc F_n$ pour tout $n$ ie si et seulement si $\{\tau= n\}\in\mc F_n$ pour tout $n$.
\bigskip 

\Def \ Tribu engendrée par un temps d'arrêt 
\sskip 
La tribu des évènements antécédents à $\tau$ est définie par:
$$\mc F_\tau =\{B\in \mc F_{\infty}|\ B\cap\{\tau = n\}\in \mc F_n, \ \forall n\}.$$
\bigskip 

\underline{Lemme:}
\sskip 
Soit $Y$ une VA $\mc F_{\infty}$-mesurable: $Y$ est $\mc F_\tau $-mesurable si et seulement si $Y1_{\tau =n}$ est $\mc F_n$-mesurable pour tout $n$.
\sskip 
Si $\E(Y)$ est bien définie, alors $\E(Y|\mc F_\tau)=\sum_{n\in\bar\N}1_{\tau =n}\E(Y|\mc F_n)$.
\bigskip

\Def 
\sskip 
Soit $(X_n)$ une suite de VA $\mathbb{F}$-adaptée, on peut alors définir: $X_\tau = \sum_{n\in\bar\N}X_n1_{\tau = n}$.
\bigskip 

\Prop \ Propriété de Markov forte 
\sskip 
Soit $(X_n)$ une \CM \ pour $\mathbb{F}$ à valeurs dans un espace $E$ discret, on note $P$ sa matrice de transition, on note $\tilde{X_k} = X_{\tau+k}$ pour tout $k$, alors, conditionnellement à $X_\tau$:
$$\mc F_\tau\bot \tilde{X_k}, \ \forall k \ \ \text{et }  (\tilde{X_k})_k \ \ \text{est une \CM \ de matrice de transition } P.$$
En temps discret, cette propriété est équivalente à la propriété de Markov faible: $((X_k)_{k\ge n}\bot\mc F_n$ sachant $X_n)$.
\bigskip 
\subsection{Martingales et Théorème de Temps d'Arrêt Optimal}
On raisonne dans toute la suite par rapport à une filtration $\mathbb{F}$.
\bigskip 

\Def \ Martingales 
\sskip 
Une suite de VAs $(M_n)$ est une $\mathbb{F}$-martingales si elle est $\mathbb{F}$-adaptée, intégrable et:
$$\forall n \in \N, \ \E(M_{n+1}|\ \mc F_n)=M_n.$$
si $\E(M_{n+1}|\ \mc F_n)\ge M_n$ alors c'est une sous-martingales, si $\E(M_{n+1}|\ \mc F_n)\le M_n$ alors c'est une sur-martingales. 
\bigskip 

\Prop 
\sskip 
Soit $(M_n)$ une martingales (respectivement une sous/sur-martingales), alors $M_n^\tau=(M_{\min(\tau,n)})$ est une martingales (respectivement une sous/sur-martingales).
\bigskip 

\Theo \ Théorème d'arrêt optimal
\sskip 
Soit $(M_n)$ une martingales, soient $\tau$ et $\nu$ des temps d'arrêt bornés tels que $\nu\le\tau$, alors $\E(M_\tau|\ \mc F_\nu)=M_\nu$.
\sskip 
Si $(M_n)$ est une sur/sous-martingales, alors on a plutôt respectivement: $\E(M_\tau|\ \mc F_\nu)\le M_\nu$ ou $\E(M_\tau|\ \mc F_\nu)\ge M_\nu$.
\bigskip 
\subsection{Inégalités de Martingales}
On introduit la notation suivante: $M_n^+ = \max(M_n,0)$.
\bigskip 

\Theo \ Inégalité maximale de Doob 
\sskip 
Soit $(M_n)$ une $\mathbb{F}$ sous-martingale et $a>0$, alors, pour tout $n\in\N$:
$$a\Prob(\max_{k\in[|0,n|]}M_k\ge a)\le\E(M_n 1_{\max_{k\in[|0,n|]}M_k\ge a})\le \E(M_n^+).$$
\bigskip 

\Prop 
\sskip 
Soit $(M_n)$ une martingale telle qu'il existe $n\in\N$ et $p>1$ tels que $M_n\in L^p$, alors, pour $c_p=(\frac{p}{p-1})^{p}$, il vient:
$$\E(\max_{k\in[|1,n|]}|M_k|^p)\le c_p\E(|M_n|^p).$$
\subsection{Convergence de Martingales}
L'objectif de cette partie est d'alléger les hypothèses du théorème d'arrêt optimal.
\bigskip 

\Theo
\sskip 
Si $(M_n)$ est une martingale (respectivement super/sous-martingale) bornée dans $L^1$, alors il existe $M_\infty$ telle que:
$$M_n\longrightarrow_{ps} M_\infty, \ \ \text{et} \ \ \E(|M_\infty|)<\pinf$$
on obtient également $\liminf\E(|M_n|)\ge\E(|M_\infty|)$.
\bigskip 

\underline{Corollaires:}
\sskip 
Si $(M_n)$ est une sous-martingale telle que $\sum_{n\in\N}\E(M_n^+)<\pinf$, alors on peut utiliser le théorème précédent sur $(M_n)$.
\sskip 
Si $(M_n)$ est une martingale positive, alors il existe $M_\infty$ telle que: $M_n\longrightarrow_{ps}M_\infty$ et $\E(M_\infty)\le\lim_{n\to\pinf}\E(M_n)$.
\bigskip 

\Theo 
\sskip 
Si $(M_n)$ est une martingale, alors les propositions suivantes sont équivalentes:
$$M_n\longrightarrow_{ps}M_\infty \ \ \text{et} \ \ M_n\longrightarrow_{L^1}M_\infty$$
$$\text{il existe } Z \ \ \text{telle que} \ \ \E(|Z|)<\pinf \ \ \text{et} \ \ M_n = \E(Z|\mc F_n)$$
dans ce cas, pour tout $n\in\N$, $M_n = \E(M_\infty|\mc F_n)$ ps, c'est une martingale dite fermée.
\bigskip 

\underline{Corollaire:}
\sskip 
Si $Z$ est une VA intégrable, alors $(\E(Z|\mc F_n))_n$ est une martingale fermée telle que: $\E(Z|\mc F_n)\to\E(Z|\mc F_\infty)$ ps et dans $L^1$.
\bskip 
On en arrive à la propriété qui fait l'objet de cette partie: 
\smallskip 

\Prop 
\sskip 
Si $(M_n)$ est une martingale fermée avec $M_\infty$ sa limite, si $\tau$ et $\nu$ sont des temps d'arrêt tels que : $\nu\le\tau$, alors:
$$\E(M_\tau|\mc F_\nu)=M_\nu.$$
\bigskip 

\Prop 
\sskip 
Si $(M_n)$ est une martingale telle que $\sum_{n\in\N}\E(|M_n|^p)<\pinf$, alors il existe $M_\infty$ telle que $(M_n)$ converge ps et dans $L^1$ vers $M_\infty$ avec $M_n = \E(M_\infty|\mc F_n)$ ps.
\smallskip 
De plus, en posant $M_\infty^+ = \sup_{n\in\N}|M_n|\in L^p$ et $c_p=(\frac{p}{p-1})^p$, alors:
$$E({M_\infty^+}^p)\le c_p\E(|M_\infty|^p) \ \ \text{et } \E(|M_\infty|^p)=\sup_{n\in\N}\E(M_n^p).$$
\section{Arrêt Optimal}
On s'intéresse à $(\Omega,\mc F, \mathbb{F}=(\mc F_n),\Prob)$ ainsi qu'à une suite de gains $(G_n)_n$ et à un horizon $N\in\bar\N$.
\sskip 
On note $\tau^N=\{\text{Temps d'arrêt} \ \ \tau \ \ \text{pour}\ \ \mathbb{F}| \ \tau\le N\}$ et $V_*=\sup_{\tau\in\tau^N}\E(G_\tau)$ le gain maximal.
\sskip 
Un temps d'arrêt $\tau$ est dit optimal si : $\E(G_\tau)=V_*$.
\bigskip 

Premier cas: $N$ est fini et $(G_n)$ est $\mathbb{F}$-adaptée, alors:
\begin{itemize}
    \item à date $N$, pas le choix: $G_N$ 
    \item à date $N-1$, choix entre $G_{N-1}$ et $\E (G_N|\mc F_{N-1})$, si $G_{N-1}>\E (G_N|\mc F_{N-1})$ on s'arrête
    \item à date $N-2$, choix entre $G_{N-2}$ et $\E(\max (G_{N-1},\E (G_N|\mc F_{N-1})|\mc F_{N-2}))$
    \item on définit alors $S_N=G_N$ et, par récurrence descendante: $S_n=\max (G_n, \E(S_{n+1}|\mc F_n))$, on note également $\tau_*=\inf\{n\in\N|\ S_n=G_n\}$ et $\tau_{**}=\inf\{n\in\N|\ S_n>\E(S_{n+1}|\mc F_n)\}$.
\end{itemize}

\Prop 
\sskip 
$\tau_*$ et $\tau_{**}$ sont des temps d'arrêt optimaux tels que $V_*=\E(G_{\tau_*}=\E(G_{\tau_{**}}))$, de plus, pour tout $\tau\in\tau^N$, $\tau$ est un temps d'arrêt optimal si et seulement si $\tau_*\le \tau\le\tau_{**}$.
\bskip 
Il est intéressant de constater que $(S_n)$ est la plus petite sur-martingale qui majore $(G_n)$.
\bigskip 

On s'intéresse désormais au second cas: l'horizon est infini, on définit alors pour une famille de VA$\R$ $(X_i)$ son majorant 'absolu' ps par:
$$\text{ess}\sup_i X_i = X_*\Leftrightarrow  \Prob(X_i\le X_*)= 1 \ \ \text{et} \ \ \exists Y : \ \Prob(Y\ge X_i)=1 \implies Y\ge X_* \ \ ps, \ \forall i.$$
On peut ainsi poser $S_n = $ess$\ \sup_{\tau\in\tau^N}\E(G_\tau|\ \mc F_n)$.
\bskip 
Dans tous les cas, on a le théorème suivant:

\Theo 
\sskip 
Si $\E(\sup_{n\in[|0,N|]}G_n^+)<\pinf$ et si ou bien $N<\pinf$, ou bien $N=\pinf$ et $\limsup G_n\le G_\infty$ ps, alors il existe un temps d'arrêt optimal.
\newpage
\section{Points A Retenir}
\subsection{Fonctions Mesurables}
On rappelle, pour $f$ de $(S, \mc S)$ dans $(E,\mc E)$: $\sigma(f)=\{f^{-1}(A), \ A\in \mc E\}$. 
\sskip 
La fonction $f$ est alors dite \underline{mesurable} si $\sigma(f)\in \mc S$.
\sskip 
En général le produit, le max et la somme de fonction mesurable est mesurable.
\sskip 
La limite simple d'une suite de fonctions mesurables est mesurable.
\sskip 
Le \underline{théorème de convergence monotone} donne, pour $(f_n)$ une suite de fonctions mesurables à valeurs réelles telle que $0\le f_n\le f_{n+1}$ \pp, alors il vient:
$$\lim \int f_nd\mu = \int\lim f_nd\mu.$$
\bigskip
\subsection{Espaces $L^p$}
Inégalités:
\begin{itemize}
    \item Hölder: pour $p,q\in(1,\pinf)$ tels que $\frac 1 p + \frac 1 q = 1$, supposons que $f\in L^p$ et $g\in L^q$, alors $fg$ est intégrable et:
    $$\int |fg|d\mu\le(\int |f|^pd\mu)^{\frac 1 p}(\int |g|^qd\mu)^{\frac 1 q}.$$
    \item CS: supposons désormais que $f$ et $g$ soient de carré intégrable, alors: 
    $$\int |fg|d\mu\le(\int |f|^2d\mu)^{\frac 1 2}(\int |g|^2d\mu)^{\frac 1 2}.$$
    \item Minkowski: soit $p\in[1,\pinf)$, on suppose que $f,g\in L^p$, alors:
    $$(\int |f+g|^pd\mu)^{\frac 1 p}\le(\int |f|^pd\mu)^{\frac 1 p}+(\int |g|^pd\mu)^{\frac 1 p}.$$
\end{itemize}
Pour $p\in[1,\pinf)$, l'\evn \ $(L^p, \ ||\cdot||_p)$ est complet.
\bigskip 

\subsection{Espérance (Conditionnelle)}
Inégalité de Tchebychev: pour $a>0$, on a: $\Prob (|X|\ge a)\le \frac{\E(X^2)}{a^2}$.
Inégalité de Jensen: pour $f$ convexe: $f(\E(X))\le\E(f(X))$.
\bskip
On rappelle la définition: une variable aléatoire $Z$, mesurable pour $\mc H$ telle que son espérance soit bien définie, est \underline{l'espérance conditionnelle de X par rapport à $\mc H$} si:
$$\E(X1_A)=\E(Z1_A), \ \forall A\in \mc H.$$
L'espérance conditionnelle de $X$ par rapport à $\mc H$ existe toujours et, par ailleurs: $\E(\E(X|\mc H))=\E(X)$.
\sskip 
La convergence dominée de Lebesgue s'écrit ici: soient $X,Y,(X_n)$ des VA$\R$ telles que $(X_n)$ converge vers $X$ \pp \ et $|X_n|\le Y$ avec $Y$ intégrable, alors on a :
$$\lim\E(X_n|\mc H)=\E(X|\mc H).$$
De plus, pour $X$ et $Y$ deux VA$\R$ telles que $\E(X)$ et $\E(XY)$ soient bien définies et que $Y$ soit $\mc H$ mesurable, alors il vient;
$$\E(XY)=\E(\E(X|\mc H)Y).$$
Propriétés importantes: 
\begin{itemize}
    \item Si $X$ est $\mc H$ mesurable, alors: $\E(X|\mc H)=X$
    \item Si $X$ est indépendante de $\mc H$, alors: $\E(X|\mc H)=\E(X)$
    \item Si $Y$ est une VA $\mc H$ mesurable telle que $\E(XY)$ soit bien définie, alors: $\E(YX|\mc H)=Y\E(X|\mc H)$
    \item Si $\mc G\subset \mc H$ est une $\sigma$-algèbre, alors: $\E(\E(X|\mc H)|\mc G)=\E(X|\mc G)$
    \item Si $A\in \mc H$, alors: $\E(X|A)=\E(X1_A)\Prob(A)$.
\end{itemize}
\bigskip 

\subsection{Chaînes de Markov discrètes}
Propriété fondamentale: conditionnellement à $X_n$, les événements $X_1,...,X_{n-1}$ et $(X_{n+k})_{k\ge0}$ sont indépendants.
\sskip 
Le processus $(X_n)$ est une chaîne de Markov qui respecte le filtre $\mathbb{F}$ si elle est adaptée pour ce filtre et si elle vérifie: pour tout n, conditionnellement à $X_n$, les événements $\mc F_n$ et $(X_{n+k})$ sont indépendants.
\sskip 
On a les équivalneces pour $(X_n)$ adaptée à $\mathbb{F}$: $(X_n)$ est une chaîne de Markov ssi pour tout $B\in\sigma((X_k)_{k\ge n})$, $\Prob (B|\mc F_n)=\Prob(B|X_n)$ pour tout n ssi $\Prob(X_{n+1}=y|\mc F_n)=\Prob(X_{n+1}=y| X_n)$ pour tout n et $y\in E$.
\sskip
Le résultat suivant est un résultat fondamental sur la construction d'une chaîne de Markov: Soient un espace mesurable $(S,\mc S)$ et $(U_n)$ une suite de VAs indépendantes à valeurs dans S. Soient $X_0$ une VA dans E indépendante de $(U_n)$ et $f$ mesurable de $E\times S$ dans $E$, alors
$$\underline{X_{n+1}=f(X_n, U_{n+1}) \ \ \text{est une chaîne de Markov.}} $$
Pour une chaîne de Markov homogène, la distribution initiale de probabilité $\mu_0$ pour $X_0$ et la matrice de transition $P$, alors:
$$\Prob(X_0=x_0,...,X_n=x_n)=\mu_0(x_0)\prod_{j=1}^nP(x_{j-1},x_j).$$
On a les propositions suivantes, pour une chaîne de Markov homogène:
\begin{itemize}
    \item $\mu_n = \mu_0P^n$
    \item $\E(f(X_n)) = \mu_0 P^n f$
    \item $\E(f(X_n)|\mc F_{n-1}) = Pf(X_{n-1})$
    \item $\E(f(X_{n+k}|X_n)) = P^kf(X_n)$
    \item $\E(X_{n+k}=y|X_n)=P^k(X_n,y)$
    \item Si $x$ est récurrent: $P(N^x=\pinf)=1$ et $\sum_n P^n(x,x)=\pinf$
    \item S'il est transient: $P(N^x<\pinf)=1$ et $\sum_n P^n(x,x)<\pinf$
    \item Les états d'une même classe d'équivalence sont ou tous transients ou tous récurrents, si la classe est ouverte, ils sont tous transients
\end{itemize}
Une chaîne de Markov irréductible est ou bien récurrente nulle/positive ou transiente.
\sskip 
Si elle est récurrente nulle ou transiente, alors il n'y a pas de probabilité invariante.
\sskip 
On a $\frac{1}{n}\sum_{k=1}^n1_{X_k=x}\longrightarrow_{ps} 1/\E_x(T^x)$.
\bskip 
Si $x$ est de périodicité $d$, alors il existe $n_0\in \N$ tel que: $\forall n\ge n_0, \ P^{nd}(x,x)>0$. Par ailleurs les éléments d'une même classe communicante sont de même période.
\bskip
Si $(X_n)$ est récurrente positive, on a les théorèmes asymptotiques suivants:
\begin{itemize}
    \item $\pi$ est la seule proba invariante de $(X_n)$ et $\pi(x)>0$ pour tout $x$
    \item pour toute fonction réelle $f$, alors $\lim_n\frac{1}{n}\sum_{k=1}^n f(X_n) = \E_\pi(f(X_n))$ presque sûrement
    \item si la chaîne est apériodique, alors on a la convergence en distribution de $X_n$ vers $\pi$ et $\lim_n\sum_{y\in E}|P^n(x,y) - \pi(y)|=0$.
\end{itemize}
\end{document}