\documentclass{article}
\usepackage{mesraccourcis}

\title{Stochastic Process and Applications}
\author{Paul Lehaut}


\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\section{Chapitre 1: Rappels}
\subsection{Mesure}
Soit ($\Omega,\mathcal{F}$) un espace mesurable.
\medskip

\Def
\smallskip 
\newline
Une fonction $\mu: \mathcal{F} \longrightarrow [0,+\infty]$ est dite $\sigma$-additive si pour toute collection dénombrable ($A_i, \ i\in I$)
d'ensembles mesurables deux à deux disjoints, on a:
$$\mu (\bigcup_{i\in I}A_i) = \sum_{i\in I}\mu(A_i).$$
\newline
Une mesure $\mu$ sur ($\Omega,\mathcal{F}$) est \sigadd, à valeur dans $[0,+\infty]$, définie sur $\mathcal{F}$ telle que:
$\mu(\varnothing)=0.$ On dit que ($\Omega,\mathcal{F}, \mu$) est un espace mesuré, $A\in \mathcal{F}$ est de mesure nulle si $\mu(A)=0$.
\newline
$\mu$ est dite $\sigma$-finie si il existe $(\Omega_n, \ n\in \mathbb{N})$ telle que:
$$\bigcup_{n\in\N}\Omega_n=\Omega \ \ \text{et} \ \ \forall n \in \N,\ \mu(\Omega_n)<+\infty.$$
\newline
Une mesure de probabilité $\Prob$ est une mesure telle que $\Prob(\Omega)=1$.
\bigskip
\newline
Soit donc $\mu$ une mesure sur ($\Omega,\mathcal{F}$).
\medskip

\Prop
\smallskip
\newline
On a les propriétés suivantes:

$$\mu(A\cup B)+ \mu(A\cap B)=\mu(A)+\mu(B)$$
$$A\subset B \implies \mu(A)\le \mu(B)$$
$$\text{Convergence monotone: pour }(A_n, \ n\in \N) \text{ telle que } \forall n\in\N , \ A_{n+1}\subset A_n, \text{ alors } \mu(\bigcup_{n\in \N}A_n)=\lim_{n\to \infty}\mu(A_n)$$
$$\text{Si } (A_i, i \in I) \text{ est une collection dénombrable d'ensembles mesurables, alors il vient: } \mu(\bigcup_{i\in I}A_i)\le \sum_{i\in I}\mu(A_i).$$
\bigskip

\Def 
\smallskip
\newline
Les événements $(A_i, i\in I)$ sont indépendants si, pour tout sous-ensemble fini $J\subset I$, on a:
$$\Prob (\bigcap_{j\in J}A_j)=\prod_{j\in J} \Prob (A_j).$$
\bigskip
\subsection{Fonctions Mesurables}
Soient $(S,\mathcal{S})$ et $(E,\mathcal{E})$ deux espaces mesurables. Soit $f$ une fonction de S dans E, alors:
$$\{f^{-1}(A), \ A\in \mathcal{E}\}=\sigma(f)$$
est une \sigalg.
\bigskip

\Def \ Fonction mesurable
\smallskip
\newline
La fonction $f$ est dite mesurable si $\sigma(f)\subset \mathcal{S}$.
\bigskip
\newline
Si $\mu$ est une mesure sur $(E,\mathcal{E})$ et que f est mesurable, alors $\mu_f=\mu\circ f^{-1}$ est une mesure sur ($S,\mathcal{S}$).
\newline
Une fonction continue définie sur un espace topologique et prenant ses valeurs dans un espace topologique est mesurable au sens de la \sigalg \ borélienne.
\newline
Pour $f$ et $g$ des fonctions mesurables à valeurs réelles définies sur le même espace mesurable, alors les fonction $fg$ et $\max (f,g)$ sont mesurables.
Si par ailleurs ses fonctions ne prennent pas de valeurs infinies, alors la fonction $f+g$ est mesurable.
\newline 
La composition de fonctions mesurables est également mesurable.
\bigskip

\Prop 
\smallskip
\newline
Soit $(f_n)$ une suite de fonctions réelles mesurables, alors les fonctions $\lim\inf f_n$ et $\lim\sup f_n$ sont mesurables, en particulier, si $(f_n)$ converge simplement, alors sa limite est mesurable.
\bigskip

\Def \ Variable Aléatoire
\sskip
Une variable aléatoire X définie de $\Omega$ dans $E$ est une fonction mesurable définie sur ($\Omega,\mathcal{F}$) à valeurs dans ($E,\mathcal{E}$).
\newline
X est dite indépendante de la \sigalg \ $\mathcal{H}$ si, pour tout $(A,B)\in \mathcal{E}\times \mathcal{H}$, les événements $\{X\in A\}$ et $B$ sont indépendants.
\bigskip
\subsection{Théorème de convergence pour l'intégration}
Soit $(f_n)$ une suite de fonctions mesurables à valeurs réelles. Cette suite converge \pp \ si $$\lim\inf f_n = \lim\sup f_n \text{ \pp.}$$
On rappelle que la limite de cette suite de fonction est alors mesurable.
\bigskip

\Theo \ Convergence monotone
\sskip 
Soit ($f_n, \ n\in \N$) une suite de fonctions mesurables à valeurs réelles telle que pour tout $n\in \N, \ 0\le f_n\le f_{n+1}$ \pp, alors il vient:
$$\lim_{n\to\infty}\int f_n d\mu=\int \lim_{n\to\infty} f_n d\mu.$$
\bskip 
Le lemme de Fatou donne, pour ($f_n, n$) une suite de fonctions mesurables et positives presque partout, alors il vient:
$$\lim\inf\int f_n d\mu\ge \int \lim\inf f_n d\mu.$$
\bigskip

\Theo \ Convergence dominée de Lebesgue
\sskip 
Soient $f, \ g$ deux fonctions à valeurs réelles mesurables, soit $(f_n)$ une suite de fonctions à valeurs réelles mesurables.
\newline
On suppose que, pout tout $n\in \N$, on a \pp \ $|f_n|\le g$, que f désigne la limite de $(f_n)$ et que g est intégrable, alors:
$$\lim_{n\to\infty}\int f_nd\mu=\int fd\mu.$$

\subsection{Espaces $L^p$}
On commence par rappeler les inégalités suivantes pour $f$ et $g$ des fonctions mesurables à valeurs réelles:
\bigskip

Inégalité de Hölder: Soient $p,g\in (1,+\infty)$ tels que $\frac{1}{p}+\frac{1}{q}=1$, supposons que $|f|^p$ et $|g|^q$ soient intégrables, alors $fg$ est intégrable et on a:
$$\int |fg|d\mu\le(\int|f|^pd\mu)^{1/p}(\int|g|^qd\mu)^{1/q}.$$
\bigskip

Inégalité de Cauchy-Schwarz: Supposons que $f$ et $g$ soient de carré intégrable, alors fg est intégrable et on a:
$$\int |fg|d\mu\le (\int f^2d\mu)^{1/2}(\int g^2d\mu)^{1/2}$$
on a égalité si et seulement si $f$ et $g$ sont propotionnelles \pp.
\bigskip

Inégalité de Minkowski: Soit $p\in [1,+\infty)$, supposons que $|f|^p$ et $|g|^p$ soient intégrables, alors on a:
$$(\int |f+g|^pd\mu)^{1/p}\le(\int |f|^pd\mu)^{1/p}+(\int |g|^pd\mu)^{1/p}.$$

\Prop 
\sskip 
Soit $p\in [1,+\infty)$, l'\evn \ ($L^p, ||\cdot||_p$) est complet.
\bigskip 

\Theo \ Fubini
\sskip 
Soient $\nu$ et $\mu$ deux mesures $\sigma$-finies respectivement sur ($E, \mathcal{E}$) et ($S, \mathcal{S}$), alors:

-il existe une unique mesure sur ($E\times S, \mathcal{E}\otimes\mathcal{S}$), notée $\nu\otimes\mu$, telle que:
$$\forall (A,B)\in \mathcal{E}\times\mathcal{S}, \ \nu\otimes\mu (A\times B)=\nu(A)\mu(B)$$
c'est la mesure produit

-Soit f une fonction à valeurs réelles défnie sur $E\times S$, alors:
$$\int f(x,y)\nu\otimes\mu(dx,dy)=\int\int f(x,y)\mu(dy)\nu(dx)=\int\int f(x,y)\nu(dx)\mu(dy).$$
\bigskip
\subsection{Espérance, Variance et Inégalités}
Soit X une variable aléatoire, soit $f$ une fonction à valeurs réelles, si $\E (f(X))$ est bien définie, alors on a:
$$\E(f(X))=\int f(x)\Prob_X(dx).$$
\bigskip

Inégalité de Tchebychev: Soit X une VA$\R$, soit, $a>0$, alors:
$$\Prob (|X|\ge a )\le \frac{E(X^2)}{a^2}.$$
\bigskip

Inégalité de Jensen: Soit X une VA$\R^d$ intégrable, soit $f$ une fonction à valeurs réelles convexe définie sur $\R^d$, alors $\E(f(X))$ est bien définie et:
$$f(\E(X))\le \E(f(X)).$$
\bigskip 

\section{Espérance Conditionnelle}
\subsection{Espérance Conditionnelle}
On s'intéresee à une VA$\R$ définie sur ($E,\mc F$) dont l'espérance est bien définie ainsi qu'à $\mc H\subset F$ une \sigalg.
\bigskip 

\Def \ Espérance conditionnelle
\sskip
On dit qu'une variable aléatoire $Z$, mesurable pour $\mc{H}$ telle que $\E(Z)$ soit bien définie, est l'espérance conditionnelle de $X$ par rapport à $\mc{H}$ si:
$$\E(X1_A)=\E(Z1_A), \ \forall A\in\mc{H}.$$
\bskip
Pour $Z$ et $Z'$ deux variables aléatoires $\mc H$ mesurables telles que leurs espérances soient bien définies et que:
$$\E(Z1_A)=\E(Z'1_A), \ \forall A\in \mc H$$
alors $Z=Z'$ \pp.
\bigskip 

\Theo \ Radon-Nikodym
\sskip 
Soient $\mu$ et $\nu$ deux mesures $\sigma$-finie sur $(\Omega, \mc H)$ telles que: $\nu(A)=0\implies\mu(A)=0$, alors il existe une fonction mesurable $f$ positive telle que:
$$\int_A fd\nu=\mu(A)$$
on note alors: $f=\frac{d\mu}{d\nu}$ et on l'appelle dérivée de Radon-Nikodym.
\bigskip 

\Prop
\sskip
Pour $X$ et $Y$ des VA$\R$ de carré intégrable alors:

-Si $X$ est positive presque partout, alors l'espérance conditionnelle de $X$ est positive presque partout.
\smallskip

-On a presque partout: $\E(aX+bY|\mc H)=a\E(X|\mc H)+ b\E(Y|\mc H)$.
\smallskip

-Soit $(X_n,\ n\in\N)$ une suite croissante de VA$\R$ positives de carré intégrable alors on a \pp :
$$\lim\E(X_n|\mc H)=\E(\lim X_n| \mc H).$$
\bigskip

\Prop 
\sskip 
L'espérance conditionnelle de $X$ par rapport à $\mc H$ existe toujours, par ailleurs on a:
$$\E(\E(X|\mc H))=\E(X)$$
donc l'intégrabilité de $X$ entraîne celle de $\E(X|\mc H)$.
\newline
\bigskip

\Prop
\smallskip

-Si $X$ est positive \pp alors son espérance conditionnelle l'est également.
\smallskip

-Si $X$ et $Y$ sont intégrables, alors, pour tout réels $a$ et $b$, on a :
$$\E(aX+bY|\mc H)=a\E(X|\mc H)+b\E(Y| \mc H)$$
et, si $X\le Y$ \pp, alors $\E(X|\mc H)\le \E(Y|\mc H)$ \pp.
\smallskip

-Soit $(X_n,\ n\in\N)$ une suite croissante de VA$\R$ positives \pp, alors on a \pp:
$$\lim\E(X_n|\mc H)=\E(\lim X_n|\mc H).$$
\smallskip

-Le lemme de Fatou s'écrit: Soit $(X_n,\ n\in\N)$ une suite de VA$\R$ positives \pp, alors on a \pp:
$$\E(\lim\inf X_n|\mc H)\le \lim\inf\E(X_n|\mc H).$$
\smallskip

-La convergence dominée de Lebesgue s'écrit: Soient $X,Y,(X_n)$ des VA$\R$ telles que $(X_n)$ converge vers $X$ \pp \ et $|X_n|\le Y$ avec $Y$ intégrable, alors on a :
$$\lim\E(X_n|\mc H)=\E(X|\mc H).$$
\bskip
Par ailleurs, les inégalités de Hölder, Cauchy-Schwarz, Minkowski et Jensen restent valables pour l'espérance conditionnelle.
\newline
De plus, pour $X$ et $Y$ deux VA$\R$ telles que $\E(X)$ et $\E(XY)$ soient bien définies et que $Y$ soit $\mc H$ mesurable, alors on a:
$$\E(XY)=\E(\E(X|\mc H)Y).$$
\bigskip

\Prop 
\sskip
On suppose X intégrable, alors:
\smallskip

-Si $X$ est $\mc H$ mesurable, alors: $\E(X|\mc H)=X$.
\smallskip 

-Si $X$ est indépendante de $\mc H$ alors: $\E(X|\mc H)=\E(X)$.
\smallskip

-Si $Y$ est une VA $\mc H$ mesurable telle que $\E(XY)$ soit bien définie, alors: $\E(YX|\mc H)=Y\E(X|\mc H)$.
\smallskip

-Si $\mc G\subset\mc H$ est une \sigalg, alors: $\E(\E(X|\mc H)|\mc G)=\E(X|\mc G)$.
\smallskip 

-Si $A\in \mc H$, alors: $\E(X|A)=\E(X1_A)\Prob(A)$.
\bigskip

\subsection{Espérance Conditionnée par une VA}
Soit $V$ une variable aléatoire définie sur $(E,\mc E)$, on note $\E(X|V)=\E(X|\sigma(V))$, si $\E(X)$ est bien définie, alors il existe une fonction mesurable $g$ définie sur E telle que: $\E(X|V)=g(V)$.
\sskip 
Si $V$ est discrète, alors:
$$g(v)=\frac{\E(X1_{V=v})}{\Prob(V=v)}=\E(X|V=v) \ \ \text{si } \Prob(V=v)>0, \ \ \text{et } g(v)=0 \ \ \text{sinon.}$$
\bigskip 

\section{Chaînes de Markov Discrètes}
Une chaîne de Markov est une suite de variables aléatoires $X=(X_n)$ qui représente l'évolution dynamique d'un système stochastique. La propriété fondamentale des chaînes de Markov est que l'état du système à l'instant $n$ ne dépend des états précédents qu'à travers $X_n$. C'est-à-dire que, conditionnellement à $X_n$, $(\ind X n)$ et $(X_{n+k})_k$ sont indépendants.
\sskip 
Dans ce qui suit on considère l'espace probabilisé $(\Omega, \mc F, \Prob)$ et l'espace $(E,\mc E)$ où $E$ est au plus dénombrable, sans précisions supplémentairtes les VAs seront définies de $\mc F$ dans $\mc E$.
\bigskip 

\subsection{Définitions et Propriétés}
Soit $X=(X_n)$ une chaîne de Markov, on définit l'ensemble des informations disponibles à l'instant $n$ par la \sigalg \ $\mc F_n$
\bigskip 

\Def \ Filtre 
\sskip 
Un filtre $\mathbb{F}=(\mc F_n)$ est une suite croissante de \sigalg \ incluses dans $\mc F$. Une suite de VAs $(X_n)$ est adaptée pour $\mathbb F$ si $X_n$ est $\mc F_n$ mesurable pour tout $n$.
\bigskip 

\Def 
\sskip 
Le processus $X=(X_n)$ est une chaîne de Markov qui respecte le filtre $\mathbb F$ si elle est adaptée pour ce filtre et si elle vérifie la propriété de Markov: pour tout $n$, conditionnellement à $X_n$, $\mc F_n$ et $(X_{n+k})_{k\in\N}$ sont indépendants.
\bigskip 

\Prop \ Définitions équivalentes
\sskip 
On suppose que $(X_n)$ est adaptée au filtre $\mathbb F$, alors on a les équivalences suivantes:
\begin{itemize}
    \item $(X_n)$ est une chaîne de Markov
    \item Pour tout $n$ et $B\in\sigma(X_k)_{k\ge n}$ on a $\Prob (B|\mc F_n)=\Prob(B|X_n)$
    \item Pour tout $n$ et $y\in E$ on a $\Prob (X_{n+1}=y|\mc F_n)=\Prob(X_{n+1}=y|X_n)$.
\end{itemize}
\bigskip
La proposition précédente nous permet d'introduire le lemme suivant: 
\smallskip

\underline{Lemme:}
\sskip 
Soient un espace mesurable $(S, \mc S)$ et $(U_n)$ une suite de VAs indépendantes à valeurs dans S. Soient $X_0$ une variable aléatoire à valeurs dans E indépendante de $(U_n)$ et $f$ une fonction mesurable définie de $E\times S$ dans $E$, on peut alors définir le système dynamique stochastique suivant: $X_{n+1}=f(X_n,U_{n+1})$ qui est une chaîne de Markov.
\newpage
\section{Points A Retenir}
\subsection{Fonctions Mesurables}
On rappelle, pour $f$ de $(S, \mc S)$ dans $(E,\mc E)$: $\sigma(f)=\{f^{-1}(A), \ A\in \mc E\}$. 
\sskip 
La fonction $f$ est alors dite \underline{mesurable} si $\sigma(f)\in \mc S$.
\sskip 
En général le produit, le max et la somme de fonction mesurable est mesurable.
\sskip 
La limite simple d'une suite de fonctions mesurables est mesurable.
\sskip 
Le \underline{théorème de convergence monotone} donne, pour $(f_n)$ une suite de fonctions mesurables à valeurs réelles telle que $0\le f_n\le f_{n+1}$ \pp, alors il vient:
$$\lim \int f_nd\mu = \int\lim f_nd\mu.$$
\bigskip
\subsection{Espaces $L^p$}
Inégalités:
\begin{itemize}
    \item Hölder: pour $p,q\in(1,\pinf)$ tels que $\frac 1 p + \frac 1 q = 1$, supposons que $f\in L^p$ et $g\in L^q$, alors $fg$ est intégrable et:
    $$\int |fg|d\mu\le(\int |f|^pd\mu)^{\frac 1 p}(\int |g|^qd\mu)^{\frac 1 q}.$$
    \item CS: supposons désormais que $f$ et $g$ soient de carré intégrable, alors: 
    $$\int |fg|d\mu\le(\int |f|^2d\mu)^{\frac 1 2}(\int |g|^2d\mu)^{\frac 1 2}.$$
    \item Minkowski: soit $p\in[1,\pinf)$, on suppose que $f,g\in L^p$, alors:
    $$(\int |f+g|^pd\mu)^{\frac 1 p}\le(\int |f|^pd\mu)^{\frac 1 p}+(\int |g|^pd\mu)^{\frac 1 p}.$$
\end{itemize}
Pour $p\in[1,\pinf)$, l'\evn \ $(L^p, \ ||\cdot||_p)$ est complet.
\bigskip 

\subsection{Espérance}
Inégalité de Tchebychev: pour $a>0$, on a: $\Prob (|X|\ge a)\le \frac{\E(X^2)}{a^2}$.
Inégalité de Jensen: pour $f$ convexe: $f(\E(X))\le\E(f(X))$.
\bigskip 
\subsubsection{Espérance Conditionnelle}
On rappelle la définition: une variable aléatoire $Z$, mesurable pour $\mc H$ telle que son espérance soit bien définie, est \underline{l'espérance conditionnelle de X par rapport à $\mc H$} si:
$$\E(X1_A)=\E(Z1_A), \ \forall A\in \mc H.$$
L'espérance conditionnelle de $X$ par rapport à $\mc H$ existe toujours et, par ailleurs: $\E(\E(X|\mc H))=\E(X)$.
\sskip 
La convergence dominée de Lebesgue s'écrit ici: soient $X,Y,(X_n)$ des VA$\R$ telles que $(X_n)$ converge vers $X$ \pp \ et $|X_n|\le Y$ avec $Y$ intégrable, alors on a :
$$\lim\E(X_n|\mc H)=\E(X|\mc H).$$
De plus, pour $X$ et $Y$ deux VA$\R$ telles que $\E(X)$ et $\E(XY)$ soient bien définies et que $Y$ soit $\mc H$ mesurable, alors il vient;
$$\E(XY)=\E(\E(X|\mc H)Y).$$
Propriétés importantes: 
\begin{itemize}
    \item Si $X$ est $\mc H$ mesurable, alors: $\E(X|\mc H)=X$
    \item Si $X$ est indépendante de $\mc H$, alors: $\E(X|\mc H)=\E(X)$
    \item Si $Y$ est une VA $\mc H$ mesurable telle que $\E(XY)$ soit bien définie, alors: $\E(YX|\mc H)=Y\E(X|\mc H)$
    \item Si $\mc G\subset \mc H$ est une $\sigma$-algèbre, alors: $\E(\E(X|\mc H)|\mc G)=\E(X|\mc G)$
    \item Si $A\in \mc H$, alors: $\E(X|A)=\E(X1_A)\Prob(A)$.
\end{itemize}

\end{document}