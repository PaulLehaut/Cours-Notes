\documentclass{article}
\usepackage{mesraccourcis}

\title{Deep Learning}
\author{Paul Lehaut}


\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage
\section{Bases du Machine Learning}
Le Machine Learning est une discipline qui vise à concevoir des algorithmes généraux applicables à de nombreux problèmes et ce en partant uniquement des données.
\sskip 
Le data engineering consiste en l'étude approfondie des données et à les rendre exploitables. Il s'agit d'une étape cruciale qui concentre une grande partie du travail dans les problèmes réelles.
\bigskip 

\subsection{Types d'apprentissage}
Selon les scénarios, il existe différents types d'apprentissage:
\begin{itemize}
    \item L'apprentissage supervisé: les données sont composées à la fois des données d'entrées et des sorties attendues. Le but est d'implémenter un algorithme capable de généraliser proprement pour de nouvelles entrées.
    \item L'apprentissage non supervisé: les données sont fournies sans les sorties attendues, il s'agit alors de trouver des structures au sein des données (typiquement à l'aide de méthodes de clustering).
    \item Il en existe encore d'autres type comme le reinforcement learning qui permet à un algorithme d'interagir avec son environnement.
\end{itemize}
\bigskip
Il faut également faire la distinction entre deux types de méthodes:
\begin{itemize}
    \item La méthode paramétrique: elle définit un ensemble de fonctions pour lesquelles il convient de trouver les meilleurs paramètres.
    \item La méthode non paramétrique: elle dépend directement des données.
\end{itemize}
\bigskip 

\subsection{Apprentissage Supervisé Paramétrique}
Soit $X$ un espace d'entrée et $Y$ un espace de sortie, on va chercher à apprendre une fonction
\newline
de prédiction: $f:X\longrightarrow Y$ paramétrée par un paramètre $\theta$.
On va donc chercher les, voire les, paramètre $\theta$ qui maximise la performance de la fonction $f$.
\sskip 
Formelement, on définit une fonction de coût $l(y',y)$, qui mesure l'erreur entre la prédiction $y'$ et la valeur attendue $y$, ainsi qu'une fonction de risque: $R(f)=\E_{(x,y)}(l(f(x),y))$.
\sskip 
Malheureusement, on ne connaît jamais la distribution réelle des données mais plutôt simplement un échantillon $Z$. On définit alors le risque empirique:
$$R_Z(f)=\frac{1}{|Z|}\sum_{(x,y)\in Z}l(f(x),y).$$
L'apprentissage consiste alors à minimiser une fonction de perte définie à partir de ce risque et, éventuellement, d'autres termes.
\bskip 
Pour éviter qu'un modèle over/underfit les données, il est souvent judicieux de séparer les données en trois sets: un pour l'entraînement (train set), un pour la validation du modèle (validation set) et enfin un pour estimer la performance rélle (test set).
\bigskip 

\section{Premier Résau de Neurones}
\subsection{Perceptron Multicouche (MLP)}
Un (MLP) est la composition de couches linéaires ($x\mapsto Wx+b$ avec $W$ le poids et $b$ le biais) et non-linéaires. Ces architectures sont caractérisées par leurs hyperparamètres (taille des couches, type de non-linéarité).
\bigskip 

\Theo \ Cybenko
\sskip 
Un MLP à 2 couches peut approximer n'importe quelle fonction continue sur un compact avec une précision arbitraire.
\bigskip 

\Def \ Fonction de perte
\sskip 
On définit la perte quadratique moyenne (MSE) adaptée à la classification multi-classe via codage one-hot par:
$$L_{MSE}(\theta,D)=\frac{1}{N}\sum_{i=1}^N||f_\theta(x_i)-y_i||^2 \ \ \text{où D correspond au dataset.}$$
Cette fonction ne cherche qu'à réduire l'erreur sur les données d'entraînement, il y a donc un risque d'overfiting, on peut donc ajouter une pénalité sur la taille des poids, on définit alors le coefficient de régularisation $\lambda>0$, la fonction à minimiser devient:
$$L(\theta,D)=L_{MSE}(\theta,D)+\lambda||\theta||^2$$
plus $\lambda$ est grand plus le résau est contraint de rester simple.
\bigskip 

\subsection{Optimisation}
Même avec un modèle simple, on obtient un problème d'optimisation non convexe, on utilise donc la descente de gradient.
\newline 
Le principe de la descente gradient est le suivant: à chaque itération, on déplace le paramètre (ici $\theta$) dans la direction opposée au gradient de la fonction de perte: $\theta\leftarrow\theta-\nu\nabla_\theta L(\theta, D)$ où $\nu$ correspond au taux d'apprentissage.
\newline
Cette technique nécessite toutefois de calculer le gradient sur toutes les données ce qui est couteux sur les grands datasets.
\bskip 
Pour contourner ce problème, on utilise la méthode de descente gradient stochastique (SGD) qui consiste à ne pas calculer le gradient sur l'ensemble des données mais à partir d'un échantillon.
\newline
Il en existe deux variantes:
\begin{itemize}
    \item SGD pur: à chaque itération on prend un seul exemple aléatoire: $\theta\leftarrow\theta -\nu\nabla_\theta l(f_\theta(x_i),y_i)$.
    \item Mini-batch SGD: à chaque itération on prend un petit lot de données (batch) de taille B:$$\theta\leftarrow\theta-\nu \frac 1 B\sum_{i=1}^B\nabla_\theta l(f(x_i),y_i).$$ Cette version est plus simple en pratique car plus stable que le SGD pur et plus efficace que le gradient complet (elle est également bien adapté au GPU).
\end{itemize}
\bigskip 

\subsection{Hyperparamètres Clés de l'Optimisation}
Les hyperparamètres clés sont:
\begin{itemize}
    \item Le taux d'apprentissage: c'est le paramètre $\nu$ qui détermine la taille des pas dans l'espace des paramètres, lorsqu'il est trop grand le modèle diverge et lorsqu'il est trop petit l'apprentissage peut être très lent voire bloqué dans un minimum local. Souvent on choisit au départ $\nu\in[10^{-3},10^{-2}]$.
    \item La taille des batch B: une trop petite taille permet de mieux explorer le paysage de la perte mais augmente l'importance du bruit, lorsqu'elle est trop grande le modèle risque d'overfit. En pratique on choisit des batch de 32 ou 64 pour les petits modèles.
    \item Le calendrier du taux d'apprentissage: le taux d'apprentissage n'est souvent pas constant, on le fait varier de diverses façons (division toutes les $x$ epochs, décroissance en forme de cosinus, augmentation au fur et à mesure etc). L'objectif est d'éviter de se retrouver coincé dans des minima locaux tout en assurant la convergence en fin d'entraînement.
    \item Le nombre d'époques (Epochs): l'algorithme voit l'ensemble des données d'entraînement en une epoch, lorsque le nombre d'epoch est trop grand le modèle risque d'overfit.
\end{itemize}
\section{Backpropagation}

La backpropagation se base essentiellement sur la règle de dérivation en chaîne. Chaque couche est vue comme pouvant faire deux choses:
\begin{itemize}
    \item Forward: Calculer sa sortie en fonction de son entrée et de ses paramètres.
    \item Backward: Calculer les gradients de la perte par rapport à ses paramètres et à son entrée.
\end{itemize}
L'algorithme se fait en deux étapes:
\begin{itemize}
    \item Forward pass: On fait passer les données à travers le réseau pour obtenir la prédiction.
    \item Backward pass: On fait revenir les gradients depuis la sortie jusqu'à l'entrée.
\end{itemize}
A la fin on a les gradients de la perte $L$ par rapport à tous les paramètres du résau, ce qui permet de le mettre à jour avec la descente de gradient.
\newline 
Par exemple pour un résau de trois couches: $x\to h_1\to h_2\to y$ on calcule en forward $h_1,h_2$ et $y$, puis en backward on remonte: $\frac{\partial L}{\partial y}$, puis $\frac{\partial L}{\partial h_2}$, ensuite $\frac{\partial L}{\partial h_1}$, et enfin les dérivées par rapport aux poids.
\bigskip 

\subsection{Formalisation}
Considérons un résau à K couches, chaque couche $f_k$ prend en entrée un vecteur $x_{k-1}$ et des paramètres $\theta_k$ pour produire une sortie:
$$x_k=f_k(x_{k-1},\theta_k)$$
la sortie finale du résaux est $y=x_K$.
\bskip 
Soit une fonction différentiable de perte $L$ pour la sortie $y$ du résau, le backward pass a pour objectif de calculer, pour tout paramètre $\theta_k$, la dérivée $\frac{\partial L}{\partial \theta_k}$, on peut alors mettre à jour la valeur de ce paramètre:
$$\theta_k\leftarrow \theta_k - \alpha \frac{\partial L}{\partial \theta_k}(\theta_k) \ \ \text{avec } \alpha \text{ le taux d'apprentissage.}$$
Pour effectuer ce calcule on calcule récurcivement $\frac{\partial L}{\partial \theta_k}$ à partir de la dernière couche:
$$\frac{\partial L}{\partial \theta_k}(\theta_k)=\frac{\partial L}{\partial x_k}(x_k)\frac{\partial f_k}{\partial \theta_k}(x_{k-1},\theta_k)$$
or, par hypothèse, $L$ est différentiable donc on peut calculer directement $\frac{\partial L}{\partial x_K}$ puis:
$$ \frac{\partial L}{\partial x_{k-1}}(x_{k-1})=\frac{\partial L}{\partial x_{k}}(x_{k})\frac{\partial x_k}{\partial x_{k-1}}=\frac{\partial L}{\partial x_{k}}(x_{k})\frac{\partial f_k}{\partial x_{k-1}}(x_{k-1}\theta_k).$$
\section{A Retenir Des Quizzs}
\subsection{Quizz 1}
\begin{itemize}
    \item Comment calculer le nombre de paramètres d'un résaux de neurones: pour chaque couche on a le calcule suivant: $y=Wx$ avec $y$ la sortie en dimension $k$, $x$ l'entrée de dimension $d$ et donc $W$ la matrice de paramètres dans $\M_{k,d}(\R)$, cette couche a donc $k*d$ paramètres. 
    \newline
    Par exemple pour un résau en trois couches dont les deux premières couches contiennent respectivement 200 et 100 neurones, pour une entrée de dimension 10 et une sortie de dimension 1, on a:
    $$\R^{10}\longrightarrow_{W_1}\R^{200}\longrightarrow_{W_2}\R^{100}\longrightarrow_{W_3}\R^1 \ \ \text{on a donc } 10\cdot200+200\cdot100+100\cdot1 \ \ \text{paramètres.}$$
    \item Calcul de la mémoire nécessaire pour implémenter le forward/backward pass: pour un résau dont les paramètres sont stoqués sur M bits et dont les données à chaque couche pour un unique échantillon sont stoquées sur m bits, la mémoire nécessaire pour implémenter le forward pass sur un batch de taille B est $$M+B\cdot m \cdot \text{nombre de couches}.$$
    Pour le backward pass, il faut également compter les paramètres du gradient qui sont d'environ un par paramètre du résau donc la mémoire nécessaire est:
    $$M+B\cdot m \cdot \text{nombre de couches}.$$
\end{itemize}
\end{document}